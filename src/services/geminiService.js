import { ChatGoogleGenerativeAI } from '@langchain/google-genai'

// Initialize with API key
const API_KEY = import.meta.env.VITE_GEMINI_API_KEY

if (!API_KEY) {
    console.error('VITE_GEMINI_API_KEY is not set in environment variables')
}

// Initialize LangChain's Google GenAI client
let chatModel = null

if (API_KEY) {
    try {
        chatModel = new ChatGoogleGenerativeAI({
            apiKey: API_KEY,
            modelName: 'gemini-2.5-flash', // Updated to latest Gemini 2.5 Flash
            temperature: 0.7,
            maxOutputTokens: 2048,
        })
        console.log('âœ… ChatGoogleGenerativeAI initialized with gemini-2.5-flash')
    } catch (error) {
        console.error('Failed to initialize ChatGoogleGenerativeAI:', error)
    }
}

/**
 * Generate embeddings for text using Gemini
 * @param {string} text - Text to embed
 * @returns {Promise<number[]>} - Embedding vector
 */
export async function createEmbedding(text) {
    if (!API_KEY) {
        throw new Error('Gemini API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ. LÃ¼tfen .env dosyasÄ±nda VITE_GEMINI_API_KEY ayarÄ±nÄ± kontrol edin')
    }

    try {
        // Use LangChain's embeddings model
        const { GoogleGenerativeAIEmbeddings } = await import('@langchain/google-genai')

        const embeddings = new GoogleGenerativeAIEmbeddings({
            apiKey: API_KEY,
            modelName: 'text-embedding-004', // Latest embedding model
        })

        const embedding = await embeddings.embedQuery(text)
        return embedding
    } catch (error) {
        console.error('Embedding error:', error)
        throw new Error(`Failed to create embedding: ${error.message}`)
    }
}

/**
 * Generate a response using LangChain's Google GenAI
 * @param {string} prompt - The prompt to send
 * @param {string} context - Context from retrieved documents
 * @param {Object} documentMetadata - Metadata about active documents
 * @returns {Promise<string>} - Generated response
 */
export async function generateResponse(prompt, context, documentMetadata = {}) {
    if (!chatModel) {
        throw new Error('Gemini API anahtarÄ± yapÄ±landÄ±rÄ±lmamÄ±ÅŸ. LÃ¼tfen .env dosyasÄ±nda VITE_GEMINI_API_KEY ayarÄ±nÄ± kontrol edin')
    }

    try {
        const fullPrompt = buildRAGPrompt(context, prompt, documentMetadata)

        console.log('ğŸ¤– Calling LangChain ChatGoogleGenerativeAI...')

        // Use LangChain's invoke method
        const response = await chatModel.invoke(fullPrompt)

        console.log('âœ… Response received from Gemini')

        // Extract text from LangChain response
        return response.content
    } catch (error) {
        console.error('Generation error:', error)

        if (error.message?.includes('API key') || error.message?.includes('401')) {
            throw new Error('GeÃ§ersiz API anahtarÄ±. LÃ¼tfen VITE_GEMINI_API_KEY deÄŸerini kontrol edin')
        }

        if (error.message?.includes('quota') || error.message?.includes('429')) {
            throw new Error('API kotasÄ± aÅŸÄ±ldÄ±. LÃ¼tfen daha sonra tekrar deneyin')
        }

        if (error.message?.includes('404')) {
            throw new Error('Model bulunamadÄ±. LÃ¼tfen API anahtarÄ±nÄ±zÄ±n Gemini modellerine eriÅŸimi olduÄŸunu doÄŸrulayÄ±n (https://aistudio.google.com/apikey)')
        }

        throw new Error(`Cevap oluÅŸturulamadÄ±: ${error.message}`)
    }
}

/**
 * Build a RAG-optimized prompt
 * @param {string} context - Retrieved context
 * @param {string} question - User question
 * @param {Object} documentMetadata - Metadata about documents
 * @returns {string} - Formatted prompt
 */
function buildRAGPrompt(context, question, documentMetadata = {}) {
    const { activeFileCount = 1, fileNames = [] } = documentMetadata

    // Detect comparison queries
    const comparisonKeywords = /compare|difference|contrast|versus|vs\.|which.*better|which.*more|both.*mention|similarities|distinctions/i
    const isComparisonQuery = comparisonKeywords.test(question)

    let basePrompt = `Sen, saÄŸlanan belge baÄŸlamÄ±na dayalÄ± olarak sorularÄ± cevaplayan yardÄ±mcÄ± bir yapay zeka asistanÄ±sÄ±n.`

    // Add comparison-specific instructions for multi-document queries
    if (isComparisonQuery && activeFileCount > 1) {
        basePrompt += `\n\nğŸ” KARÅILAÅTIRMA MODU AKTÄ°F:
KullanÄ±cÄ± birden fazla belgeyi karÅŸÄ±laÅŸtÄ±rmak/zÄ±tlaÅŸtÄ±rmak istiyor: ${fileNames.join(', ')}.

KarÅŸÄ±laÅŸtÄ±rma sorularÄ±nÄ± cevaplarken:
- Hangi bilginin hangi belgeden geldiÄŸini aÃ§Ä±kÃ§a belirt
- Benzerlikleri VE farklÄ±lÄ±klarÄ± vurgula
- Kaynaklara atÄ±fta bulunurken belge adlarÄ±nÄ± kullan
- Sadece ayrÄ± Ã¶zetler deÄŸil, karÅŸÄ±laÅŸtÄ±rmalÄ± bir analiz sun
- Bir belge bir konuda daha fazla detaya sahipse, bunu aÃ§Ä±kÃ§a belirt`
    }

    return `${basePrompt}

BELGELERDEN BAÄLAM:
${context}

KULLANICI SORUSU:
${question}

TALÄ°MATLAR:
- Soruyu YALNIZCA yukarÄ±daki baÄŸlamda saÄŸlanan bilgilere dayanarak cevapla
- Cevap baÄŸlamda bulunamazsa, "Bu bilgi saÄŸlanan belgelerde bulunamadÄ±" de
- AÃ§Ä±k ve kapsamlÄ± ol
- MÃ¼mkÃ¼n olduÄŸunda belirli alÄ±ntÄ±lar veya referanslar kullan
- Soru net deÄŸilse, aÃ§Ä±klama iste
- CevabÄ± TÃ¼rkÃ§e olarak ver

CEVAP:`
}
